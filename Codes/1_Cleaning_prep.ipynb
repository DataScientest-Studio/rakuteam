{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1_Cleaning_prep.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mf3FfNk0cMaK",
        "outputId": "5d1af840-326e-422b-e805-9a678d9b20ee"
      },
      "source": [
        "#CONNEXION à google drive\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/Drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uHIUmAO7MB-"
      },
      "source": [
        "#PARAMETRES!!!\n",
        "isSaveData = False\n",
        "pathSaveCsv = '/Drive/My Drive'\n",
        "isRegenerateKeywords = False\n",
        "isManualDataFrame=False\n",
        "import re  \n",
        "import requests\n",
        "import io\n",
        "import pandas as pd\n",
        "from nltk.tokenize import PunktSentenceTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk as nltk"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTRv0Qc5Tzgy"
      },
      "source": [
        "def creerDataframePourArticleManuel(madescription, madesignation):\n",
        "  dic={\"designation\":[madesignation],\"description\":[madescription],\"productid\":0,\"imageid\":None,\"prdtypecode\":None}\n",
        "  X=pd.DataFrame(dic)\n",
        "  return X"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06fCX3rF8lMy"
      },
      "source": [
        "#CHARGEMENT des fichiers\n",
        "def load_X(isManualDataFrame,madescription, madesignation):\n",
        "  if (not isManualDataFrame):\n",
        "    url = \"https://raw.githubusercontent.com/JulienJ-44/rakuteam/main/Datasets/Dataset_challenge.csv\"\n",
        "    download = requests.get(url).content\n",
        "    X=pd.read_csv(io.StringIO(download.decode('utf-8')), index_col=0)\n",
        "  else:\n",
        "    #OU création d'un dataframe\n",
        "    X=creerDataframePourArticleManuel(madescription, madesignation)\n",
        "  return X"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Mpns_jzcqqg"
      },
      "source": [
        "def cleaningX_to_df(X):\n",
        "  #PREPARATION: FUSION de X et y et remplacement des VALEURS MANQUANTES par \"\"\n",
        "  df = X.drop(['imageid'], axis = 1)#\n",
        "  #on joint X et y\n",
        "  #df = pd.merge(df1, y, left_index=True, right_index=True)\n",
        "\n",
        "  #valeurs MANQUANTES\n",
        "  df['description']=df['description'].fillna(\"\")\n",
        "  df['designation']=df['designation'].fillna(\"\")\n",
        "  #turn all text to LOWER case\n",
        "  df['description'] = df['description'].str.lower()\n",
        "  df['designation'] = df['designation'].str.lower()\n",
        "\n",
        "  #recodage des caractères HTML\n",
        "  df.replace([\"&eacute;\",\"&egrave;\",\"&euml;\",\"&ecirc;\",\"&ocirc;\",\"&ugrave;\",\"&ccedil;\",\"&agrave;\",\"&nbsp;\",\"&amp;\",\"&#39;\",\"'\",'n°']\n",
        "            , [\"é\",\"è\",\"ë\",\"ê\",\"ô\",\"ù\",\"ç\",\"à\",\" \",\"&\",\" \",\" \",'numéro '], inplace=True, regex=True)\n",
        "\n",
        "  \"\"\"\n",
        "  Return the text in lower case after removing html tags\n",
        "  \"\"\"    \n",
        "  def pre_process(text):\n",
        "      # lowercase\n",
        "      #text=text.lower()\n",
        "      #remove tags\n",
        "      text=re.sub('<.*?>',\" \",text) \n",
        "      return text\n",
        "\n",
        "  df['description'] = df['description'].apply(lambda x:pre_process(x))\n",
        "  df['designation'] = df['designation'].apply(lambda x:pre_process(x))\n",
        "  return df"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnoO3ijYdDNH"
      },
      "source": [
        "# Download the stopwords\n",
        "def get_stopwords():\n",
        "  #utiliser @st.cache !!! pour STREAMLIT\n",
        "  nltk.download('punkt') #télécharge les paquets language (dont FR)\n",
        "  nltk.download('stopwords')\n",
        "  #Ajoute des stopwords à la liste française prédéfinie\n",
        "  stop_words = set(stopwords.words('french'))\n",
        "  stop_words.update(stopwords.words('english'))\n",
        "  stop_words.update(stopwords.words('german'))\n",
        "  stop_words.update(['-','de','en','pour','la','(',')','the','/li','/strong','strong','and','non','eacute','comme','cette','of'])\n",
        "  return stop_words\n",
        "\n",
        "#FONCTION pour supprimer les mots inutiles\n",
        "def filtrer_mots_inutiles(texte,lststopwords):\n",
        "  \"\"\"\n",
        "  Fonction pour transformer un texte en une suite de mots séparés par des espaces\n",
        "  et en excluant les stopwords et les mots de moins de 2 caractères\n",
        "  \"\"\"\n",
        "  mots = word_tokenize(texte, language='french')\n",
        "  tokens = []\n",
        "  for mot in mots:\n",
        "    if (mot not in lststopwords and len(mot)>1):\n",
        "      tokens.append(mot.lower())\n",
        "  mastring=\" \".join(tokens)\n",
        "  return mastring"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0nxcdfu9Ep2"
      },
      "source": [
        "#3 ways to clean data\n",
        "\n",
        "def clean_manualdata(madescription, madesignation):\n",
        "  \"\"\"\n",
        "  input: madescription & madesignation are used\n",
        "  \"\"\"\n",
        "  X=load_X(True, madescription, madesignation)\n",
        "  df=cleaningX_to_df(X)\n",
        "  stopwords=get_stopwords()\n",
        "  df['designation']= df['designation'].apply(lambda x: filtrer_mots_inutiles(x, stopwords))\n",
        "  df['description']= df['description'].apply(lambda x: filtrer_mots_inutiles(x, stopwords))\n",
        "  return df\n",
        "\n",
        "def clean_data():\n",
        "  \"\"\"\n",
        "  load data from file and clean it\n",
        "  \"\"\"\n",
        "  X=load_X(False, \"\", \"\")\n",
        "  df=cleaningX_to_df(X)\n",
        "  stopwords=get_stopwords()\n",
        "  df['designation']= df['designation'].apply(lambda x: filtrer_mots_inutiles(x, stopwords))\n",
        "  df['description']= df['description'].apply(lambda x: filtrer_mots_inutiles(x, stopwords))\n",
        "  return df\n",
        "\n",
        "def load_data_cleaned():\n",
        "  \"\"\"\n",
        "  load dataset_challenge_cleaned.csv\n",
        "  \"\"\"\n",
        "  df= pd.read_csv(f'{pathSaveCsv}/dataset_challenge_cleaned.csv')\n",
        "  df['designation']=df['designation'].fillna(\"\")\n",
        "  #valeurs MANQUANTES\n",
        "  df['description']=df['description'].fillna(\"\")\n",
        "  return df"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoRkGCR0FH81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        },
        "outputId": "8db2faac-b77e-4ac6-968b-2d7691237bb4"
      },
      "source": [
        "#TEST function clean_manualdata()\n",
        "madescription=\"voici ma description d'article\"\n",
        "madesignation=\"voici ma désignation d'article\"\n",
        "df=clean_manualdata(madescription, madesignation)\n",
        "df"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>designation</th>\n",
              "      <th>description</th>\n",
              "      <th>productid</th>\n",
              "      <th>prdtypecode</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>voici désignation article</td>\n",
              "      <td>voici description article</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 designation                description  productid prdtypecode\n",
              "0  voici désignation article  voici description article          0        None"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NM9v4Hd1FAnS"
      },
      "source": [
        "#TEST2 function clean_data()\n",
        "df=clean_data() #same can be done by df=pd.read_csv(f'{pathSaveCsv}/dataset_challenge_cleaned.csv')\n",
        "df\n",
        "if (isSaveData):\n",
        "  df.to_csv(f'{pathSaveCsv}/dataset_challenge_cleaned.csv')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQmCNqVTJS2O"
      },
      "source": [
        "#DEBUT PREPROCESSING\n",
        "isManualData=True\n",
        "isRegenerateKeywords=False"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5ZAK9-ErXir"
      },
      "source": [
        "#IDF (\"inverse de fréquence de document\")\n",
        "#formule: log(nbr d articles / nb d articles dans lequels le terme apparaît)\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "if (isRegenerateKeywords):\n",
        "  #transformation de la colonne en type liste\n",
        "  words_desi=df['designation'].tolist()\n",
        "  #words_desc=df['description'].tolist()\n",
        "\n",
        "  # create object \n",
        "  vect  = TfidfVectorizer()  \n",
        "  # get tf-df values \n",
        "  result = vect.fit_transform(words_desi) \n",
        "  # get idf values \n",
        "  #sorted_vocabulary = dict(sorted(vect.vocabulary_.items(), key=lambda item: item[0], reverse=True))\n",
        "  #print(vect.vocabulary_)\n",
        "  #print(vect.get_feature_names())\n",
        "  #print(vect.idf_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQ2Q55dWrXzP"
      },
      "source": [
        "if (isRegenerateKeywords):\n",
        "  #fonctions de manipulation des TFIDF\n",
        "  def sort_coo(coo_matrix):\n",
        "      tuples = zip(coo_matrix.col, coo_matrix.data)\n",
        "      return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n",
        "\n",
        "  def extract_topn_from_vector(feature_names, sorted_items, topn=10):\n",
        "      \"\"\"get the feature names and tf-idf score of top n items\"\"\"\n",
        "      \n",
        "      #use only topn items from vector\n",
        "      sorted_items = sorted_items[:topn]\n",
        "\n",
        "      score_vals = []\n",
        "      feature_vals = []\n",
        "      \n",
        "      # word index and corresponding tf-idf score\n",
        "      for idx, score in sorted_items:\n",
        "          \n",
        "          #keep track of feature name and its corresponding score\n",
        "          score_vals.append(round(score, 3))\n",
        "          feature_vals.append(feature_names[idx])\n",
        "\n",
        "      #create a tuples of feature,score\n",
        "      #results = zip(feature_vals,score_vals)\n",
        "      results= {}\n",
        "      for idx in range(len(feature_vals)):\n",
        "          results[feature_vals[idx]]=score_vals[idx]\n",
        "      \n",
        "      return results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmBCM64udEYa"
      },
      "source": [
        "if (isRegenerateKeywords):\n",
        "  #TF fréquence du terme dans l ensbl de la categorie d articles\n",
        "  feature_names=vect.get_feature_names()\n",
        "  #on étudie le champ designation ( à remplacer par \"description\" si besoin)\n",
        "  colonneClass = \"designation\" \n",
        "  class_text_cols = []\n",
        "  #on parcourt la liste des codes de classes\n",
        "  lst_keywords_byclass={}\n",
        "  classes_codes = (df['prdtypecode'].value_counts().index.tolist())\n",
        "  #classes_codes=[2583, 1220, 22240, ...]\n",
        "  for class_code in classes_codes:\n",
        "    #on copie dans un df les lignes correspondant au code de classe actuel\n",
        "    df_class = df[df[\"prdtypecode\"]==class_code]\n",
        "    #on joint tous les élements de la colonne dans une chaîne\n",
        "    class_text = ' '.join(df_class[colonneClass])\n",
        "    #affichage des infos de la classe\n",
        "    print(\"Classe:\", class_code, \"\\n\", len(df_class.index), \" éléments\")\n",
        "    #tfidf\n",
        "    class_text_encode = vect.transform([class_text])\n",
        "    \n",
        "    #sort the tf-idf vectors by descending order of scores\n",
        "    sorted_items=sort_coo(class_text_encode.tocoo())\n",
        "    #extract only the top n; n here is 10\n",
        "    keywords=extract_topn_from_vector(feature_names,sorted_items,15)\n",
        "    # now print the results\n",
        "    print(\"===Keywords===\")\n",
        "    for k in keywords:\n",
        "        print(k,keywords[k])\n",
        "    lst_keywords_byclass[class_code]=keywords\n",
        "    print(\"\\n\")\n",
        "\n",
        "  #lst_keywords_byclass contient: {1180:[mot1 mot2 mot3 ...], 2520:[mot1 mot2 mot3 ...] ...}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMUujTrk-I00"
      },
      "source": [
        "#SAUVEGARDES des 15 keyword par classe\n",
        "import pickle\n",
        "if (isRegenerateKeywords):\n",
        "  dict = lst_keywords_byclass\n",
        "  f = open(f'{pathSaveCsv}/dico_keywords_tfidf_15.pkl',\"wb\")\n",
        "  pickle.dump(dict,f)\n",
        "  f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNuCNtI3OB92"
      },
      "source": [
        "#CHARGEMENT des 15 keyword par classe\n",
        "import pickle\n",
        "\n",
        "def load_keywords_fromfile():\n",
        "  # reading the dictionnary des 15 keyword\n",
        "  with open(f'{pathSaveCsv}/dico_keywords_tfidf_15.pkl', 'rb') as handle: \n",
        "    data = handle.read() \n",
        "  # reconstructing the data as dictionary \n",
        "  lst_keywords_byclass = pickle.loads(data) \n",
        "  return lst_keywords_byclass\n",
        "\n",
        "lst_keywords_byclass = load_keywords_fromfile()"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EE99mCYx9Jmv"
      },
      "source": [
        "#TEMP df_sample!!!\n",
        "#df_sample=df.head(1000) #TEMP!!!!\n",
        "#la liste des keywords stockés par classe a été limitée à 10, faut il aller plus loin, performances?\n",
        "\"\"\"\n",
        "Fontion de scoring qui renvoie un score selon le nombre d'occurences des mots et leur score idf\n",
        "texte: texte à lire mot à mot pour scorer les mots\n",
        "dict_keywords_idf:dictionnaire des keywords/idf d'une des classes produits\n",
        "\"\"\"\n",
        "import re\n",
        "def scoring(texte, dict_keywords_idf):\n",
        "#texte = texte de la désignaton/description de l'article\n",
        "#dict_keywords_idf = [mot1 mot2 mot3 ...]\n",
        "  #print(texte)\n",
        "  #print(dict_keywords_idf)\n",
        "  score = 0.0\n",
        "  for keyword_key,keyword_idf in dict_keywords_idf.items():\n",
        "    nb_occur = len(re.findall(keyword_key, texte, flags=re.IGNORECASE))\n",
        "    score += nb_occur*keyword_idf\n",
        "  #print(score)\n",
        "  return score"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3K5cNOM9Koz"
      },
      "source": [
        "def add_bestidf(df):\n",
        "  col_start=7\n",
        "  df[\"best_idf\"]=df.iloc[:,col_start:].idxmax(axis=1)\n",
        "  #df[\"best_idf\"]= [2583 if (s.sum()==0) else df.iloc[:,col_start:].idxmax(axis=1) for s in df.iloc[:,1col_start1:]]\n",
        "  #gestion des cas où toutes les colonnes valent 0\n",
        "  #on affecte la classe 2583 (majoritaire)\n",
        "  for i in range(len(df)):\n",
        "    sum = df.iloc[i,col_start:].sum()\n",
        "    if (sum == 0):\n",
        "      df[\"best_idf\"][i]=\"2583\"\n",
        "  return df"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlYyzCLxNQ0P"
      },
      "source": [
        "#Tokenisation (Séparation du texte en phrases et mots) du champ \"designation\"\n",
        "import nltk\n",
        "from nltk.tokenize import PunktSentenceTokenizer\n",
        "\n",
        "def add_nb_phrases(df):\n",
        "  #en phrases\n",
        "  tokenizer = PunktSentenceTokenizer()\n",
        "  df['desi_nb_phrases']= df['designation'].apply(lambda x: len(tokenizer.tokenize(str(x))))\n",
        "  df['desc_nb_phrases']= df['description'].apply(lambda x: len(tokenizer.tokenize(str(x))))\n",
        "  #en mots\n",
        "  #df['desi_nb_mots+']= df['designation'].apply(lambda x: len(x.split(\" \"))\n",
        "  #df['desc_nb_mots+']= df['description'].apply(lambda x: len(x.split(\" \"))\n",
        "  return df"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwCdBCpE_hXp"
      },
      "source": [
        "#Expressions régulières pour identifier les différentes unités\n",
        "#TODO transformer en numérique pas en liste\n",
        "import re\n",
        "\n",
        "def add_regex1(df):\n",
        "  #nombre de nombres à 2 chiffres ou +\n",
        "  r = re.compile(\"[0-9]{2,}\") \n",
        "  df['desi_nb2chiffres+']= df['designation'].apply(lambda x: min(1,len(r.findall(x))))\n",
        "  df['desc_nb2chiffres+']= df['description'].apply(lambda x: min(1,len(r.findall(x))))\n",
        "  #XGo ou XMo ou XTo\n",
        "  #r = re.compile(\"([\\d.]+)\\s?(go|mo|to|Go|Mo|To|giga|gigas)\") \n",
        "  #df['desi_Go']=df['designation'].apply(lambda x: min(1,len(r.findall(x))))\n",
        "  #df['desc_Go']=df['description'].apply(lambda x: min(1,len(r.findall(x))))\n",
        "  #N°X\n",
        "  r = re.compile(\"(numéro )\") \n",
        "  df['desi_num']=df['designation'].apply(lambda x: min(1,len(r.findall(x))))\n",
        "  df['desi_num']=df['designation'].apply(lambda x: min(1,len(r.findall(x))))\n",
        "  #r = re.compile(\"[Nn][°]\\s?[\\d]+\") \n",
        "  #df['desi_num']=df['designation'].apply(lambda x: min(1,len(r.findall(x))))\n",
        "  #df['desc_num']=df['description'].apply(lambda x: min(1,len(r.findall(x))))\n",
        "  #Poids kg Kg mg g\n",
        "  r = re.compile(\"[0-9\\.]+[kKm]?[g]\") #([\\d.]+)\\s+(lbs?|oz|g|kg) \n",
        "  r = re.compile(\"([\\d.]+)\\s?(KG|Kg|g|kg|mg)[\\s.]\") #(nombres ou .)+ / (espace)+ / (kg mg ..)\n",
        "  df['desi_poids']=df['designation'].apply(lambda x: min(1,len(r.findall(x))))\n",
        "  df['desc_poids']=df['description'].apply(lambda x: min(1,len(r.findall(x))))\n",
        "  #Taille cm mm m\n",
        "  r = re.compile(\"([\\d.]+)\\s?(cm|mm|m|M)[\\s.]\") \n",
        "  df['desi_long']=df['designation'].apply(lambda x: min(1,len(r.findall(x))))\n",
        "  df['desc_long']=df['description'].apply(lambda x: min(1,len(r.findall(x))))\n",
        "  #Volume mL cL dL\n",
        "  r = re.compile(\"([\\d.]+)\\s?(mL|L|ml|l|cl)[\\s.]\") \n",
        "  df['desi_vol']=df['designation'].apply(lambda x: min(1,len(r.findall(x))))\n",
        "  df['desc_vol']=df['description'].apply(lambda x: min(1,len(r.findall(x))))\n",
        "  #Age\n",
        "  r = re.compile(\"([\\d.]+)\\s?(an|ans|An|Ans|mois|Mois)[\\s.]\") \n",
        "  df['desi_ans_mois']=df['designation'].apply(lambda x: min(1,len(r.findall(x))))\n",
        "  df['desc_ans_mois']=df['description'].apply(lambda x: min(1,len(r.findall(x))))\n",
        "  #Pièces\n",
        "  r = re.compile(\"([\\d.]+)\\s?(pc|pcs|pièces|pièce)[\\s.]\") \n",
        "  df['desi_pieces']=df['designation'].apply(lambda x: min(1,len(r.findall(x))))\n",
        "  df['desc_pieces']=df['description'].apply(lambda x: min(1,len(r.findall(x))))\n",
        "  #%\n",
        "  #r = re.compile(\"([\\d.]+)\\s?%\") \n",
        "  #df['desi_pourcent']=df['designation'].apply(lambda x: min(1,len(r.findall(x))))\n",
        "  #df['desc_pourcent']=df['description'].apply(lambda x: min(1,len(r.findall(x))))\n",
        "  return df"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSLGvHt49K2C"
      },
      "source": [
        "import re\n",
        "def add_regex2(df) :\n",
        "    df['desi_word_count'] = df['designation'].apply(lambda x : len(str(x).split()))\n",
        "    df['desi_char_count (w/o space)'] = df['designation'].apply(lambda x : len(x.replace(\" \",\"\")))\n",
        "    #df['desi_word_density'] = df['desi_word_count'] / (df['desi_char_count'] + 1)\n",
        "    df['desi_total_length'] = df['designation'].apply(len)\n",
        "    #df['desi_capitals'] = df['designation'].apply(lambda comment: sum(1 for c in comment if c.isupper()))\n",
        "    # df['desi_caps_vs_length'] = df.apply(lambda row: float(row['desi_capitals'])/float(row['desi_total_length']),axis=1)\n",
        "    df['desi_num_exclamation_marks'] =df['designation'].apply(lambda x: x.count('!'))\n",
        "    df['desi_num_question_marks'] = df['designation'].apply(lambda x: x.count('?'))\n",
        "    #df['desi_num_punctuation'] = df['designation'].apply(lambda x: sum(x.count(w) for w in '.,;:'))\n",
        "    #df['desi_num_symbols'] = df['designation'].apply(lambda x: sum(str(x).count(w) for w in '*&$%+-/'))\n",
        "    df['desi_num_unique_words'] = df['designation'].apply(lambda x: len(set(w for w in x.split())))\n",
        "    df['desi_words_vs_unique'] = df['desi_num_unique_words'] / df['desi_word_count']\n",
        "    df[\"desi_word_unique_percent\"] =  df[\"desi_num_unique_words\"]*100/df['desi_word_count']\n",
        "    \n",
        "    df['descri_word_count'] = df['description'].apply(lambda x : len(str(x).split()))\n",
        "    df['descri_char_count (w/o space)'] = df['description'].apply(lambda x : len(str(x).replace(\" \",\"\")))\n",
        "    #df['descri_word_density'] = df['descri_word_count'] / (df['descri_char_count'] + 1)\n",
        "    df['descri_total_length'] = df['description'].apply(lambda x :len(str(x)))\n",
        "   # df['descri_capitals'] = df['description'].apply(lambda comment: sum(1 for c in str(comment) if c.isupper()))\n",
        "    # df['descri_caps_vs_length'] = df.apply(lambda row: float(row['descri_capitals'])/float(row['descri_total_length']),axis=1)\n",
        "    df['descri_num_exclamation_marks'] =df['description'].apply(lambda x: str(x).count('!'))\n",
        "    df['descri_num_question_marks'] = df['description'].apply(lambda x: str(x).count('?'))\n",
        "    #df['descri_num_punctuation'] = df['description'].apply(lambda x: sum(str(x).count(w) for w in '.,;:'))\n",
        "   # df['descri_num_symbols'] = df['description'].apply(lambda x: sum(str(x).count(w) for w in '*&$%'))\n",
        "    df['descri_num_unique_words'] = df['description'].apply(lambda x: len(set(w for w in str(x).split())))\n",
        "    df['descri_words_vs_unique'] = df['descri_num_unique_words'] / df['descri_word_count']\n",
        "    df[\"descri_word_unique_percent\"] =  df[\"descri_num_unique_words\"]*100/df['descri_word_count']\n",
        "    return df"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "140lzzTZKvhs",
        "outputId": "575ecd00-6ee5-4b60-890b-320509150005"
      },
      "source": [
        "def create_features_loadedd(df):\n",
        "  df=add_nb_phrases(df)\n",
        "  df[\"best_idf\"]=0\n",
        "  #lst_keywords_byclass contient: {1180:[mot1 mot2 mot3 ...], 2520:[mot1 mot2 mot3 ...] ...}\n",
        "  #lst_keywords_byclass = sorted(lst_keywords_byclass)\n",
        "  for (key_kw, value_kw) in sorted(lst_keywords_byclass.items()):\n",
        "    #key_kw=1180\n",
        "    #value_kw=[mot1 mot2 mot3 ...]\n",
        "    df['class_'+str(key_kw)]=df['designation'].apply(lambda x: scoring(x, value_kw))\n",
        "  df=add_bestidf(df)\n",
        "  df=add_regex1(df)\n",
        "  df=add_regex2(df)\n",
        "  return df\n",
        "\n",
        "#TEST   create_features_loadeddf\n",
        "isManualData=False\n",
        "if (not isManualData):\n",
        "  url = \"https://raw.githubusercontent.com/JulienJ-44/rakuteam/main/Datasets/dataset_challenge_cleaned.csv\"\n",
        "  download = requests.get(url).content\n",
        "  df = pd.read_csv(io.StringIO(download.decode('utf-8')), index_col=0)\n",
        "  df=df.drop(\"Unnamed: 0.1\", axis=1)\n",
        "  df['designation']=df['designation'].fillna(\"\")\n",
        "  #valeurs MANQUANTES\n",
        "  df['description']=df['description'].fillna(\"\")\n",
        "  df=create_features_loadedd(df)\n",
        "df.head()"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>designation</th>\n",
              "      <th>description</th>\n",
              "      <th>productid</th>\n",
              "      <th>prdtypecode</th>\n",
              "      <th>desi_nb_phrases</th>\n",
              "      <th>desc_nb_phrases</th>\n",
              "      <th>best_idf</th>\n",
              "      <th>class_10.0</th>\n",
              "      <th>class_40.0</th>\n",
              "      <th>class_50.0</th>\n",
              "      <th>class_60.0</th>\n",
              "      <th>class_1140.0</th>\n",
              "      <th>class_1160.0</th>\n",
              "      <th>class_1180.0</th>\n",
              "      <th>class_1280.0</th>\n",
              "      <th>class_1281.0</th>\n",
              "      <th>class_1300.0</th>\n",
              "      <th>class_1301.0</th>\n",
              "      <th>class_1302.0</th>\n",
              "      <th>class_1320.0</th>\n",
              "      <th>class_1560.0</th>\n",
              "      <th>class_1920.0</th>\n",
              "      <th>class_1940.0</th>\n",
              "      <th>class_2060.0</th>\n",
              "      <th>class_2220.0</th>\n",
              "      <th>class_2280.0</th>\n",
              "      <th>class_2403.0</th>\n",
              "      <th>class_2462.0</th>\n",
              "      <th>class_2522.0</th>\n",
              "      <th>class_2582.0</th>\n",
              "      <th>class_2583.0</th>\n",
              "      <th>class_2585.0</th>\n",
              "      <th>class_2705.0</th>\n",
              "      <th>class_2905.0</th>\n",
              "      <th>desi_nb2chiffres+</th>\n",
              "      <th>desc_nb2chiffres+</th>\n",
              "      <th>desi_num</th>\n",
              "      <th>desi_poids</th>\n",
              "      <th>desc_poids</th>\n",
              "      <th>desi_long</th>\n",
              "      <th>desc_long</th>\n",
              "      <th>desi_vol</th>\n",
              "      <th>desc_vol</th>\n",
              "      <th>desi_ans_mois</th>\n",
              "      <th>desc_ans_mois</th>\n",
              "      <th>desi_pieces</th>\n",
              "      <th>desc_pieces</th>\n",
              "      <th>desi_word_count</th>\n",
              "      <th>desi_char_count (w/o space)</th>\n",
              "      <th>desi_total_length</th>\n",
              "      <th>desi_num_exclamation_marks</th>\n",
              "      <th>desi_num_question_marks</th>\n",
              "      <th>desi_num_unique_words</th>\n",
              "      <th>desi_words_vs_unique</th>\n",
              "      <th>desi_word_unique_percent</th>\n",
              "      <th>descri_word_count</th>\n",
              "      <th>descri_char_count (w/o space)</th>\n",
              "      <th>descri_total_length</th>\n",
              "      <th>descri_num_exclamation_marks</th>\n",
              "      <th>descri_num_question_marks</th>\n",
              "      <th>descri_num_unique_words</th>\n",
              "      <th>descri_words_vs_unique</th>\n",
              "      <th>descri_word_unique_percent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>olivia personalisiertes notizbuch 150 seiten p...</td>\n",
              "      <td></td>\n",
              "      <td>3804725264</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>class_2522.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.157</td>\n",
              "      <td>0.115</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.190</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.115</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.021</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>70</td>\n",
              "      <td>79</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>journal arts numéro 133 28/09/2001 art marche ...</td>\n",
              "      <td></td>\n",
              "      <td>436067568</td>\n",
              "      <td>2280.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>class_2280.0</td>\n",
              "      <td>0.518</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.265</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.176</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.338</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.301</td>\n",
              "      <td>0.235</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.272</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "      <td>134</td>\n",
              "      <td>156</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "      <td>0.956522</td>\n",
              "      <td>95.652174</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>grand stylet ergonomique bleu gamepad nintendo...</td>\n",
              "      <td>pilot style touch pen marque speedlink stylet ...</td>\n",
              "      <td>201115110</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>class_2462.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.275</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.144</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.625</td>\n",
              "      <td>0.657</td>\n",
              "      <td>0.297</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.020</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>63</td>\n",
              "      <td>72</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>70</td>\n",
              "      <td>469</td>\n",
              "      <td>538</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>53</td>\n",
              "      <td>0.757143</td>\n",
              "      <td>75.714286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>peluche donald europe disneyland 2000 marionne...</td>\n",
              "      <td></td>\n",
              "      <td>50418756</td>\n",
              "      <td>1280.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>class_1280.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.222</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>49</td>\n",
              "      <td>55</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>guerre tuques</td>\n",
              "      <td>luc idées grandeur veut organiser jeu guerre b...</td>\n",
              "      <td>278535884</td>\n",
              "      <td>2705.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>class_2705.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.111</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>19</td>\n",
              "      <td>111</td>\n",
              "      <td>129</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>100.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         designation  ... descri_word_unique_percent\n",
              "0  olivia personalisiertes notizbuch 150 seiten p...  ...                        NaN\n",
              "1  journal arts numéro 133 28/09/2001 art marche ...  ...                        NaN\n",
              "2  grand stylet ergonomique bleu gamepad nintendo...  ...                  75.714286\n",
              "3  peluche donald europe disneyland 2000 marionne...  ...                        NaN\n",
              "4                                      guerre tuques  ...                 100.000000\n",
              "\n",
              "[5 rows x 63 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0gQP4LrdEC3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "5a4b9fc3-c1da-4494-cabc-c268d5aa39ac"
      },
      "source": [
        "def add_features_to_manualdf(df):\n",
        "  df=add_nb_phrases(df)\n",
        "  df[\"best_idf\"]=0\n",
        "  #lst_keywords_byclass contient: {1180:[mot1 mot2 mot3 ...], 2520:[mot1 mot2 mot3 ...] ...}\n",
        "  #lst_keywords_byclass = sorted(lst_keywords_byclass)\n",
        "  for (key_kw, value_kw) in sorted(lst_keywords_byclass.items()):\n",
        "    #key_kw=1180\n",
        "    #value_kw=[mot1 mot2 mot3 ...]\n",
        "    df['class_'+str(key_kw)]=df['designation'].apply(lambda x: scoring(x, value_kw))\n",
        "  df=add_bestidf(df)\n",
        "  df=add_regex1(df)\n",
        "  df=add_regex2(df)\n",
        "  return df\n",
        "\n",
        "#TEST  add_features_to_manualdf\n",
        "isManualData=True\n",
        "if (isManualData):\n",
        "  madescription=\"\"\n",
        "  madesignation=\"bébé\"\n",
        "  df=clean_manualdata(madescription, madesignation)\n",
        "  add_features_to_manualdf(df)\n",
        "df.head()"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>designation</th>\n",
              "      <th>description</th>\n",
              "      <th>productid</th>\n",
              "      <th>prdtypecode</th>\n",
              "      <th>desi_nb_phrases</th>\n",
              "      <th>desc_nb_phrases</th>\n",
              "      <th>best_idf</th>\n",
              "      <th>class_10.0</th>\n",
              "      <th>class_40.0</th>\n",
              "      <th>class_50.0</th>\n",
              "      <th>class_60.0</th>\n",
              "      <th>class_1140.0</th>\n",
              "      <th>class_1160.0</th>\n",
              "      <th>class_1180.0</th>\n",
              "      <th>class_1280.0</th>\n",
              "      <th>class_1281.0</th>\n",
              "      <th>class_1300.0</th>\n",
              "      <th>class_1301.0</th>\n",
              "      <th>class_1302.0</th>\n",
              "      <th>class_1320.0</th>\n",
              "      <th>class_1560.0</th>\n",
              "      <th>class_1920.0</th>\n",
              "      <th>class_1940.0</th>\n",
              "      <th>class_2060.0</th>\n",
              "      <th>class_2220.0</th>\n",
              "      <th>class_2280.0</th>\n",
              "      <th>class_2403.0</th>\n",
              "      <th>class_2462.0</th>\n",
              "      <th>class_2522.0</th>\n",
              "      <th>class_2582.0</th>\n",
              "      <th>class_2583.0</th>\n",
              "      <th>class_2585.0</th>\n",
              "      <th>class_2705.0</th>\n",
              "      <th>class_2905.0</th>\n",
              "      <th>desi_nb2chiffres+</th>\n",
              "      <th>desc_nb2chiffres+</th>\n",
              "      <th>desi_num</th>\n",
              "      <th>desi_poids</th>\n",
              "      <th>desc_poids</th>\n",
              "      <th>desi_long</th>\n",
              "      <th>desc_long</th>\n",
              "      <th>desi_vol</th>\n",
              "      <th>desc_vol</th>\n",
              "      <th>desi_ans_mois</th>\n",
              "      <th>desc_ans_mois</th>\n",
              "      <th>desi_pieces</th>\n",
              "      <th>desc_pieces</th>\n",
              "      <th>desi_word_count</th>\n",
              "      <th>desi_char_count (w/o space)</th>\n",
              "      <th>desi_total_length</th>\n",
              "      <th>desi_num_exclamation_marks</th>\n",
              "      <th>desi_num_question_marks</th>\n",
              "      <th>desi_num_unique_words</th>\n",
              "      <th>desi_words_vs_unique</th>\n",
              "      <th>desi_word_unique_percent</th>\n",
              "      <th>descri_word_count</th>\n",
              "      <th>descri_char_count (w/o space)</th>\n",
              "      <th>descri_total_length</th>\n",
              "      <th>descri_num_exclamation_marks</th>\n",
              "      <th>descri_num_question_marks</th>\n",
              "      <th>descri_num_unique_words</th>\n",
              "      <th>descri_words_vs_unique</th>\n",
              "      <th>descri_word_unique_percent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bébé</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>class_1320.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.134</td>\n",
              "      <td>0.113</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.324</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.468</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  designation description  ...  descri_words_vs_unique descri_word_unique_percent\n",
              "0        bébé              ...                     NaN                        NaN\n",
              "\n",
              "[1 rows x 63 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2x9VFofBR1V"
      },
      "source": [
        "df.to_csv(f'{pathSaveCsv}/features_texte.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
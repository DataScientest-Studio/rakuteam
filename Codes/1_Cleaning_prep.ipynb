{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1_Cleaning_prep.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mf3FfNk0cMaK",
        "outputId": "121b130b-19e0-4f3a-cce0-487267fa9c7e"
      },
      "source": [
        "#CONNEXION à google drive\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/Drive')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /Drive; to attempt to forcibly remount, call drive.mount(\"/Drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uHIUmAO7MB-"
      },
      "source": [
        "#PARAMETRES!!!\n",
        "isSaveData = False\n",
        "pathSaveCsv = '/Drive/My Drive'\n",
        "isRegenerateKeywords = False\n",
        "isManualDataFrame=False\n",
        "madescription=\"voici ma description d'article\"\n",
        "madesignation=\"voici ma désignation d'article\"\n",
        "import re  \n",
        "import requests\n",
        "import io"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTRv0Qc5Tzgy"
      },
      "source": [
        "def creerDataframePourArticleManuel(madescription, madesignation):\n",
        "  dic={\"designation\":[madesignation],\"description\":[madescription],\"productid\":0,\"imageid\":None,\"prdtypecode\":None}\n",
        "  X=pd.DataFrame(dic)\n",
        "  return X\n",
        "  \n",
        "#CHARGEMENT des fichiers\n",
        "if (not isManualDataFrame):\n",
        "  url = \"https://raw.githubusercontent.com/JulienJ-44/rakuteam/main/Datasets/Dataset_challenge.csv\"\n",
        "  download = requests.get(url).content\n",
        "  X=pd.read_csv(io.StringIO(download.decode('utf-8')))\n",
        "else:\n",
        "  #OU création d'un dataframe\n",
        "  X=creerDataframePourArticleManuel(madescription, madesignation)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "gH22NmkiT5XT",
        "outputId": "70b18c95-531d-4dcd-be17-29733d490e19"
      },
      "source": [
        "X.head()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>designation</th>\n",
              "      <th>description</th>\n",
              "      <th>productid</th>\n",
              "      <th>imageid</th>\n",
              "      <th>prdtypecode</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Olivia: Personalisiertes Notizbuch / 150 Seite...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3804725264</td>\n",
              "      <td>1263597046</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>436067568</td>\n",
              "      <td>1008141237</td>\n",
              "      <td>2280.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Grand Stylet Ergonomique Bleu Gamepad Nintendo...</td>\n",
              "      <td>PILOT STYLE Touch Pen de marque Speedlink est ...</td>\n",
              "      <td>201115110</td>\n",
              "      <td>938777978</td>\n",
              "      <td>50.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Peluche Donald - Europe - Disneyland 2000 (Mar...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>50418756</td>\n",
              "      <td>457047496</td>\n",
              "      <td>1280.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>La Guerre Des Tuques</td>\n",
              "      <td>Luc a des id&amp;eacute;es de grandeur. Il veut or...</td>\n",
              "      <td>278535884</td>\n",
              "      <td>1077757786</td>\n",
              "      <td>2705.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ... prdtypecode\n",
              "0           0  ...        10.0\n",
              "1           1  ...      2280.0\n",
              "2           2  ...        50.0\n",
              "3           3  ...      1280.0\n",
              "4           4  ...      2705.0\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Mpns_jzcqqg"
      },
      "source": [
        "\n",
        "#y = pd.read_csv(\"/Drive/My Drive/Colab/Y_train_CVw08PX.csv\", index_col=0) \n",
        "\n",
        "#stockage de tous les codes de classe dans une liste\n",
        "#classes_codes = (y['prdtypecode'].value_counts().index.tolist())\n",
        "\n",
        "#PREPARATION: FUSION de X et y et remplacement des VALEURS MANQUANTES par \"\"\n",
        "df = X.drop(['imageid'], axis = 1)#\n",
        "#on joint X et y\n",
        "#df = pd.merge(df1, y, left_index=True, right_index=True)\n",
        "\n",
        "#valeurs MANQUANTES\n",
        "df['description']=df['description'].fillna(\"\")\n",
        "df['designation']=df['designation'].fillna(\"\")\n",
        "#turn all text to LOWER case\n",
        "df['description'] = df['description'].str.lower()\n",
        "df['designation'] = df['designation'].str.lower()\n",
        "\n",
        "#recodage des caractères HTML\n",
        "df.replace([\"&eacute;\",\"&egrave;\",\"&euml;\",\"&ecirc;\",\"&ocirc;\",\"&ugrave;\",\"&ccedil;\",\"&agrave;\",\"&nbsp;\",\"&amp;\",\"&#39;\",\"'\",'n°']\n",
        "           , [\"é\",\"è\",\"ë\",\"ê\",\"ô\",\"ù\",\"ç\",\"à\",\" \",\"&\",\" \",\" \",'numéro '], inplace=True, regex=True)\n",
        "\n",
        "\"\"\"\n",
        "Return the text in lower case after removing html tags\n",
        "\"\"\"    \n",
        "def pre_process(text):\n",
        "    # lowercase\n",
        "    #text=text.lower()\n",
        "    #remove tags\n",
        "    text=re.sub('<.*?>',\" \",text) \n",
        "    return text\n",
        "\n",
        "df['description'] = df['description'].apply(lambda x:pre_process(x))\n",
        "df['designation'] = df['designation'].apply(lambda x:pre_process(x))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnoO3ijYdDNH",
        "outputId": "b60d0d74-8e50-493d-e533-59d7ab3ba669"
      },
      "source": [
        "#FONCTION pour supprimer les mots inutiles\n",
        "# Download the stopwords\n",
        "from nltk.tokenize import PunktSentenceTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk as nltk\n",
        "#utiliser @st.cache !!! pour STREAMLIT\n",
        "nltk.download('punkt') #télécharge les paquets language (dont FR)\n",
        "nltk.download('stopwords')\n",
        "\n",
        "#Ajoute des stopwords à la liste française prédéfinie\n",
        "stop_words = set(stopwords.words('french'))\n",
        "stop_words.update(stopwords.words('english'))\n",
        "stop_words.update(stopwords.words('german'))\n",
        "stop_words.update(['-','de','en','pour','la','(',')','the','/li','/strong','strong','and','non','eacute','comme','cette','of'])\n",
        "\n",
        "def filtrer_mots_inutiles(texte):\n",
        "  \"\"\"\n",
        "  Fonction pour transformer un texte en une suite de mots séparés par des espaces\n",
        "  et en excluant les stopwords et les mots de moins de 2 caractères\n",
        "  \"\"\"\n",
        "  mots = word_tokenize(texte, language='french')\n",
        "  tokens = []\n",
        "  for mot in mots:\n",
        "    if (mot not in stop_words and len(mot)>1):\n",
        "      tokens.append(mot.lower())\n",
        "  mastring=\" \".join(tokens)\n",
        "  return mastring\n",
        "\n",
        "df['designation']= df['designation'].apply(lambda x: filtrer_mots_inutiles(x))\n",
        "df['description']= df['description'].apply(lambda x: filtrer_mots_inutiles(x))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LRWqt0SdD3g"
      },
      "source": [
        "if (isSaveData):\n",
        "  df.to_csv(f'{pathSaveCsv}/dataset_challenge_cleaned.csv')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0gQP4LrdEC3"
      },
      "source": [
        "#DEBUT PREPROCESSING\n",
        "if (isSaveData):\n",
        "  df=pd.read_csv(f'{pathSaveCsv}/dataset_challenge_cleaned.csv')\n",
        "df['designation']=df['designation'].fillna(\"\")\n",
        "#valeurs MANQUANTES\n",
        "df['description']=df['description'].fillna(\"\")"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bARJ2zbqdENW"
      },
      "source": [
        "#Tokenisation (Séparation du texte en phrases et mots) du champ \"designation\"\n",
        "\n",
        "#en phrases\n",
        "tokenizer = PunktSentenceTokenizer()\n",
        "df['desi_nb_phrases']= df['designation'].apply(lambda x: len(tokenizer.tokenize(str(x))))\n",
        "df['desc_nb_phrases']= df['description'].apply(lambda x: len(tokenizer.tokenize(str(x))))\n",
        "#en mots\n",
        "#df['desi_nb_mots+']= df['designation'].apply(lambda x: len(x.split(\" \"))\n",
        "#df['desc_nb_mots+']= df['description'].apply(lambda x: len(x.split(\" \"))"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5ZAK9-ErXir"
      },
      "source": [
        "#IDF (\"inverse de fréquence de document\")\n",
        "#formule: log(nbr d articles / nb d articles dans lequels le terme apparaît)\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "if (isRegenerateKeywords):\n",
        "  #transformation de la colonne en type liste\n",
        "  words_desi=df['designation'].tolist()\n",
        "  #words_desc=df['description'].tolist()\n",
        "\n",
        "  # create object \n",
        "  vect  = TfidfVectorizer()  \n",
        "  # get tf-df values \n",
        "  result = vect.fit_transform(words_desi) \n",
        "  # get idf values \n",
        "  #sorted_vocabulary = dict(sorted(vect.vocabulary_.items(), key=lambda item: item[0], reverse=True))\n",
        "  #print(vect.vocabulary_)\n",
        "  #print(vect.get_feature_names())\n",
        "  #print(vect.idf_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQ2Q55dWrXzP"
      },
      "source": [
        "if (isRegenerateKeywords):\n",
        "  #fonctions de manipulation des TFIDF\n",
        "  def sort_coo(coo_matrix):\n",
        "      tuples = zip(coo_matrix.col, coo_matrix.data)\n",
        "      return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n",
        "\n",
        "  def extract_topn_from_vector(feature_names, sorted_items, topn=10):\n",
        "      \"\"\"get the feature names and tf-idf score of top n items\"\"\"\n",
        "      \n",
        "      #use only topn items from vector\n",
        "      sorted_items = sorted_items[:topn]\n",
        "\n",
        "      score_vals = []\n",
        "      feature_vals = []\n",
        "      \n",
        "      # word index and corresponding tf-idf score\n",
        "      for idx, score in sorted_items:\n",
        "          \n",
        "          #keep track of feature name and its corresponding score\n",
        "          score_vals.append(round(score, 3))\n",
        "          feature_vals.append(feature_names[idx])\n",
        "\n",
        "      #create a tuples of feature,score\n",
        "      #results = zip(feature_vals,score_vals)\n",
        "      results= {}\n",
        "      for idx in range(len(feature_vals)):\n",
        "          results[feature_vals[idx]]=score_vals[idx]\n",
        "      \n",
        "      return results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmBCM64udEYa"
      },
      "source": [
        "if (isRegenerateKeywords):\n",
        "  #TF fréquence du terme dans l ensbl de la categorie d articles\n",
        "  feature_names=vect.get_feature_names()\n",
        "  #on étudie le champ designation ( à remplacer par \"description\" si besoin)\n",
        "  colonneClass = \"designation\" \n",
        "  class_text_cols = []\n",
        "  #on parcourt la liste des codes de classes\n",
        "  lst_keywords_byclass={}\n",
        "  classes_codes = (df['prdtypecode'].value_counts().index.tolist())\n",
        "  #classes_codes=[2583, 1220, 22240, ...]\n",
        "  for class_code in classes_codes:\n",
        "    #on copie dans un df les lignes correspondant au code de classe actuel\n",
        "    df_class = df[df[\"prdtypecode\"]==class_code]\n",
        "    #on joint tous les élements de la colonne dans une chaîne\n",
        "    class_text = ' '.join(df_class[colonneClass])\n",
        "    #affichage des infos de la classe\n",
        "    print(\"Classe:\", class_code, \"\\n\", len(df_class.index), \" éléments\")\n",
        "    #tfidf\n",
        "    class_text_encode = vect.transform([class_text])\n",
        "\n",
        "    \n",
        "    #sort the tf-idf vectors by descending order of scores\n",
        "    sorted_items=sort_coo(class_text_encode.tocoo())\n",
        "    #extract only the top n; n here is 10\n",
        "    keywords=extract_topn_from_vector(feature_names,sorted_items,15)\n",
        "    # now print the results\n",
        "    print(\"===Keywords===\")\n",
        "    for k in keywords:\n",
        "        print(k,keywords[k])\n",
        "    lst_keywords_byclass[class_code]=keywords\n",
        "    print(\"\\n\")\n",
        "\n",
        "  #lst_keywords_byclass contient: {1180:[mot1 mot2 mot3 ...], 2520:[mot1 mot2 mot3 ...] ...}"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMUujTrk-I00"
      },
      "source": [
        "#SAUVEGARDES des 15 keyword par classe\n",
        "import pickle\n",
        "if (isSaveData):\n",
        "  dict = lst_keywords_byclass\n",
        "  f = open(f'{pathSaveCsv}/dico_keywords_tfidf_15.pkl',\"wb\")\n",
        "  pickle.dump(dict,f)\n",
        "  f.close()"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c_PvXYE_R4f",
        "outputId": "35e21e30-7f2d-4838-e4f1-4eca5eaf4b55"
      },
      "source": [
        "if (not isSaveData):\n",
        "  print(pathSaveCsv)\n",
        "  # reading the dictionnary des 15 keyword\n",
        "  with open(f'{pathSaveCsv}/dico_keywords_tfidf_15.pkl', 'rb') as handle: \n",
        "      data = handle.read() \n",
        "  print(\"Data type before reconstruction : \", type(data)) \n",
        "  # reconstructing the data as dictionary \n",
        "  lst_keywords_byclass = pickle.loads(data) \n",
        "  print(\"Data type after reconstruction : \", type(lst_keywords_byclass)) \n",
        "print(lst_keywords_byclass) "
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/Drive/My Drive\n",
            "Data type before reconstruction :  <class 'bytes'>\n",
            "Data type after reconstruction :  <class 'dict'>\n",
            "{2583.0: {'piscine': 0.58, 'kit': 0.288, 'bâche': 0.243, 'spa': 0.194, 'pompe': 0.161, 'bulles': 0.154, 'intex': 0.148, 'cm': 0.137, 'ronde': 0.123, 'acier': 0.12, 'gonflable': 0.12, 'filtration': 0.111, 'gré': 0.111, 'filtre': 0.106, 'bois': 0.106}, 1560.0: {'cm': 0.271, 'matelas': 0.224, 'cuisine': 0.222, 'table': 0.172, 'chaise': 0.164, 'blanc': 0.157, 'bois': 0.15, 'tissu': 0.146, 'rangement': 0.141, 'salle': 0.128, 'fournitures': 0.123, 'design': 0.115, 'sommier': 0.115, 'gris': 0.114, 'pieds': 0.113}, 1300.0: {'générique': 0.603, 'rc': 0.338, 'drone': 0.312, 'dji': 0.241, 'quadcopter': 0.157, 'mavic': 0.143, 'avion': 0.128, 'fpv': 0.127, 'caméra': 0.119, 'maquette': 0.118, 'voiture': 0.112, 'wifi': 0.108, 'car': 0.089, 'pro': 0.089, 'batterie': 0.085}, 2060.0: {'led': 0.293, 'noël': 0.26, 'décoration': 0.229, 'lampe': 0.228, 'décor': 0.204, 'bricolage': 0.171, 'peinture': 0.161, 'lumière': 0.156, 'diamant': 0.138, 'broderie': 0.124, 'mur': 0.124, '5d': 0.122, 'chambre': 0.118, 'bain': 0.118, '3d': 0.117}, 2522.0: {'notes': 0.477, 'carnet': 0.313, 'journal': 0.272, 'bloc': 0.252, 'cahier': 0.225, 'lot': 0.212, 'mm': 0.193, 'classique': 0.191, 'a5': 0.19, 'papier': 0.127, 'a4': 0.124, 'stylo': 0.12, 'noir': 0.097, 'feuilles': 0.09, 'bleu': 0.085}, 1280.0: {'enfants': 0.328, 'jouet': 0.28, 'jouets': 0.274, 'peluche': 0.222, 'doudou': 0.219, 'toy': 0.215, 'rc': 0.176, 'puzzle': 0.168, 'cadeau': 0.143, 'voiture': 0.135, 'bébé': 0.134, 'doll': 0.132, 'poupée': 0.109, 'stress': 0.107, 'modèle': 0.104}, 2403.0: {'lot': 0.625, 'livres': 0.368, 'numéro': 0.235, 'tomes': 0.204, 'volumes': 0.172, 'tome': 0.14, 'partitions': 0.137, 'revues': 0.124, 'collection': 0.121, 'vol': 0.092, 'livre': 0.088, 'numéros': 0.086, 'histoire': 0.083, 'revue': 0.083, 'année': 0.08}, 2280.0: {'numéro': 0.797, '01': 0.221, 'france': 0.12, '03': 0.105, '11': 0.104, 'journal': 0.097, '06': 0.097, '09': 0.096, '04': 0.096, '02': 0.095, '05': 0.093, '07': 0.092, 'paris': 0.09, '10': 0.089, 'revue': 0.086}, 1920.0: {'coussin': 0.511, 'taie': 0.399, 'oreiller': 0.361, 'home': 0.225, 'canapé': 0.215, 'décor': 0.176, 'couverture': 0.154, 'sofa': 0.147, 'throw': 0.145, 'housse': 0.132, 'case': 0.132, 'coton': 0.13, 'cover': 0.124, 'décoration': 0.121, 'pillow': 0.104}, 1160.0: {'carte': 0.435, 'yu': 0.307, 'oh': 0.301, 'gi': 0.301, 'vf': 0.233, 'mtg': 0.229, 'magic': 0.226, 'rare': 0.195, 'commune': 0.159, 'pokemon': 0.142, 'pokémon': 0.141, 'numéro': 0.135, 'fr': 0.13, 'dragon': 0.127, 'reverse': 0.1}, 1320.0: {'bébé': 0.468, 'sac': 0.363, 'bavoir': 0.237, 'poussette': 0.202, 'imprimé': 0.176, 'rose': 0.157, 'bleu': 0.144, 'cm': 0.136, 'lit': 0.13, 'siège': 0.125, 'mode': 0.12, 'blanc': 0.115, 'auto': 0.108, 'enfant': 0.105, 'bandoulière': 0.104}, 10.0: {'tome': 0.308, 'edition': 0.24, 'numéro': 0.221, 'guide': 0.197, 'histoire': 0.181, 'book': 0.121, 'vie': 0.117, 'france': 0.117, 'art': 0.099, 'life': 0.091, 'collection': 0.091, 'new': 0.086, 'volume': 0.085, 'édition': 0.079, 'cours': 0.076}, 2705.0: {'tome': 0.52, 'vie': 0.182, 'histoire': 0.159, 'petit': 0.119, 'guerre': 0.111, 'amour': 0.106, 'monde': 0.102, 'comment': 0.097, 'france': 0.092, 'livre': 0.09, 'temps': 0.09, 'mort': 0.082, 'homme': 0.08, 'siècle': 0.079, 'français': 0.077}, 1140.0: {'figurine': 0.641, 'pop': 0.329, 'star': 0.202, 'wars': 0.194, 'funko': 0.182, 'shirt': 0.155, 'cm': 0.154, 'figure': 0.128, 'pvc': 0.125, 'marvel': 0.115, 'figurines': 0.097, 'gundam': 0.092, 'dragon': 0.09, 'mug': 0.087, 'japan': 0.084}, 2582.0: {'jardin': 0.417, 'cm': 0.273, 'gris': 0.192, 'tente': 0.187, 'pvc': 0.17, 'kitchen': 0.156, 'blanc': 0.152, 'table': 0.144, 'm²': 0.135, 'extérieur': 0.123, 'noir': 0.11, 'parasol': 0.109, 'résine': 0.105, 'largeur': 0.104, 'imperméable': 0.102}, 40.0: {'import': 0.57, 'jeu': 0.281, 'allemand': 0.264, 'magideal': 0.258, 'pc': 0.243, 'japonais': 0.201, 'edition': 0.188, 'version': 0.122, 'xbox': 0.115, 'jap': 0.105, 'nintendo': 0.1, 'anglais': 0.099, 'complet': 0.091, 'japon': 0.084, 'ds': 0.076}, 2585.0: {'aspirateur': 0.3, 'tools': 0.205, 'outil': 0.2, 'longueur': 0.185, 'largeur': 0.178, 'tondeuse': 0.168, 'vhbw': 0.163, 'microns': 0.157, 'mm': 0.147, 'arrosage': 0.145, 'jardin': 0.14, 'vert': 0.125, '50': 0.115, 'camion': 0.1, '10': 0.1}, 1302.0: {'stream': 0.514, 'pêche': 0.337, 'stress': 0.178, 'lampe': 0.175, 'bracelet': 0.171, 'ligne': 0.168, 'leurres': 0.146, 'led': 0.125, 'jouet': 0.122, 'trampoline': 0.11, 'lente': 0.107, 'parfumée': 0.102, 'rising': 0.101, 'torche': 0.101, 'montre': 0.099}, 1281.0: {'jeu': 0.366, 'enfants': 0.339, 'game': 0.275, 'jouets': 0.238, 'toy': 0.21, 'cartes': 0.197, 'jouet': 0.192, 'slime': 0.158, 'card': 0.127, 'cadeau': 0.127, 'board': 0.125, 'bois': 0.116, 'stress': 0.114, 'bébé': 0.113, 'puzzle': 0.109}, 50.0: {'nintendo': 0.351, 'manette': 0.269, 'ps4': 0.263, 'jeu': 0.242, 'console': 0.221, 'xbox': 0.184, 'switch': 0.178, 'playstation': 0.173, 'protection': 0.148, 'controller': 0.129, 'wii': 0.129, 'sony': 0.115, 'sans': 0.114, 'one': 0.114, 'usb': 0.112}, 2462.0: {'jeux': 0.492, 'jeu': 0.256, 'xbox': 0.252, 'lot': 0.246, 'playstation': 0.23, 'pc': 0.222, 'wii': 0.218, 'nintendo': 0.193, 'ps3': 0.184, '360': 0.166, 'console': 0.151, 'voir': 0.151, 'manettes': 0.149, 'photos': 0.143, 'neuf': 0.142}, 2905.0: {'téléchargement': 0.776, 'jeu': 0.584, 'extension': 0.111, 'edition': 0.094, 'dlc': 0.084, 'collector': 0.055, 'deluxe': 0.038, 'pack': 0.038, 'édition': 0.032, 'mac': 0.024, 'simulator': 0.024, 'iii': 0.021, 'iv': 0.021, 'mystery': 0.021, 'ii': 0.02}, 60.0: {'jeu': 0.495, 'console': 0.407, 'jeux': 0.287, 'portable': 0.281, 'vidéo': 0.28, 'rétro': 0.253, 'lecteur': 0.182, 'pouces': 0.167, 'mini': 0.164, 'intégré': 0.152, 'poche': 0.137, 'tv': 0.134, 'bits': 0.117, 'écran': 0.091, 'classique': 0.091}, 2220.0: {'chien': 0.572, 'pet': 0.373, 'chat': 0.303, 'vêtements': 0.224, 'collier': 0.192, 'dog': 0.185, 'animaux': 0.15, 'chiot': 0.133, 'chiens': 0.132, 'magideal': 0.124, 'puppy': 0.123, 'gilet': 0.106, 'cat': 0.096, 'aquarium': 0.095, 'réglable': 0.093}, 1301.0: {'chaussettes': 0.506, 'auucne': 0.395, 'bébé': 0.324, 'filles': 0.256, 'garçons': 0.21, 'cartoon': 0.203, 'anti': 0.167, 'enfants': 0.166, 'né': 0.161, 'nouveau': 0.137, 'slip': 0.136, 'billard': 0.123, 'harrows': 0.116, 'tout': 0.105, 'bébés': 0.101}, 1940.0: {'bio': 0.472, 'café': 0.222, 'capsules': 0.192, 'chocolat': 0.18, 'sachet': 0.179, 'thé': 0.152, 'gr': 0.148, '250g': 0.113, 'lot': 0.112, 'gusto': 0.111, '16': 0.111, 'dosettes': 0.107, 'dolce': 0.107, 'sucre': 0.101, 'huile': 0.099}, 1180.0: {'warhammer': 0.445, 'heroclix': 0.296, 'masque': 0.234, '40000': 0.18, 'prince': 0.176, 'figurine': 0.171, 'oop': 0.156, 'august': 0.153, '40k': 0.144, 'miniatures': 0.144, '17ml': 0.141, 'métal': 0.134, 'dragons': 0.133, 'pot': 0.114, 'space': 0.111}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EE99mCYx9Jmv"
      },
      "source": [
        "#TEMP df_sample!!!\n",
        "#df_sample=df.head(1000) #TEMP!!!!\n",
        "#la liste des keywords stockés par classe a été limitée à 10, faut il aller plus loin, performances?\n",
        "\"\"\"\n",
        "Fontion de scoring qui renvoie un score selon le nombre d'occurences des mots et leur score idf\n",
        "texte: texte à lire mot à mot pour scorer les mots\n",
        "dict_keywords_idf:dictionnaire des keywords/idf d'une des classes produits\n",
        "\"\"\"\n",
        "import re\n",
        "def scoring(texte, dict_keywords_idf):\n",
        "#texte = texte de la désignaton/description de l'article\n",
        "#dict_keywords_idf = [mot1 mot2 mot3 ...]\n",
        "  #print(texte)\n",
        "  #print(dict_keywords_idf)\n",
        "  score = 0.0\n",
        "  for keyword_key,keyword_idf in dict_keywords_idf.items():\n",
        "    nb_occur = len(re.findall(keyword_key, texte, flags=re.IGNORECASE))\n",
        "    score += nb_occur*keyword_idf\n",
        "  #print(score)\n",
        "  return score\n",
        "\n",
        "df[\"best_idf\"]=0\n",
        "#lst_keywords_byclass contient: {1180:[mot1 mot2 mot3 ...], 2520:[mot1 mot2 mot3 ...] ...}\n",
        "#lst_keywords_byclass = sorted(lst_keywords_byclass)\n",
        "for (key_kw, value_kw) in sorted(lst_keywords_byclass.items()):\n",
        "  #key_kw=1180\n",
        "  #value_kw=[mot1 mot2 mot3 ...]\n",
        "  df['class_'+str(key_kw)]=df['designation'].apply(lambda x: scoring(x, value_kw))"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "_khLnpXt9KcL",
        "outputId": "1a6b83cc-99a2-4bcc-e714-32faed85e051"
      },
      "source": [
        "#df = df.drop(['Unnamed: 0','Unnamed: 0.1'], axis=1)\n",
        "df.head()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>designation</th>\n",
              "      <th>description</th>\n",
              "      <th>productid</th>\n",
              "      <th>prdtypecode</th>\n",
              "      <th>desi_nb_phrases</th>\n",
              "      <th>desc_nb_phrases</th>\n",
              "      <th>best_idf</th>\n",
              "      <th>class_10.0</th>\n",
              "      <th>class_40.0</th>\n",
              "      <th>class_50.0</th>\n",
              "      <th>class_60.0</th>\n",
              "      <th>class_1140.0</th>\n",
              "      <th>class_1160.0</th>\n",
              "      <th>class_1180.0</th>\n",
              "      <th>class_1280.0</th>\n",
              "      <th>class_1281.0</th>\n",
              "      <th>class_1300.0</th>\n",
              "      <th>class_1301.0</th>\n",
              "      <th>class_1302.0</th>\n",
              "      <th>class_1320.0</th>\n",
              "      <th>class_1560.0</th>\n",
              "      <th>class_1920.0</th>\n",
              "      <th>class_1940.0</th>\n",
              "      <th>class_2060.0</th>\n",
              "      <th>class_2220.0</th>\n",
              "      <th>class_2280.0</th>\n",
              "      <th>class_2403.0</th>\n",
              "      <th>class_2462.0</th>\n",
              "      <th>class_2522.0</th>\n",
              "      <th>class_2582.0</th>\n",
              "      <th>class_2583.0</th>\n",
              "      <th>class_2585.0</th>\n",
              "      <th>class_2705.0</th>\n",
              "      <th>class_2905.0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>olivia personalisiertes notizbuch 150 seiten p...</td>\n",
              "      <td></td>\n",
              "      <td>3804725264</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.157</td>\n",
              "      <td>0.115</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.190</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.115</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>journal arts numéro 133 28/09/2001 art marche ...</td>\n",
              "      <td></td>\n",
              "      <td>436067568</td>\n",
              "      <td>2280.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.518</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.265</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.176</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.338</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.301</td>\n",
              "      <td>0.235</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.272</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>grand stylet ergonomique bleu gamepad nintendo...</td>\n",
              "      <td>pilot style touch pen marque speedlink stylet ...</td>\n",
              "      <td>201115110</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.275</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.144</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.625</td>\n",
              "      <td>0.657</td>\n",
              "      <td>0.297</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>peluche donald europe disneyland 2000 marionne...</td>\n",
              "      <td></td>\n",
              "      <td>50418756</td>\n",
              "      <td>1280.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.222</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>guerre tuques</td>\n",
              "      <td>luc idées grandeur veut organiser jeu guerre b...</td>\n",
              "      <td>278535884</td>\n",
              "      <td>2705.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.111</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ... class_2905.0\n",
              "0           0  ...        0.021\n",
              "1           1  ...        0.000\n",
              "2           2  ...        0.020\n",
              "3           3  ...        0.000\n",
              "4           4  ...        0.000\n",
              "\n",
              "[5 rows x 35 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "W3K5cNOM9Koz",
        "outputId": "a9728e5a-3ae2-4677-e1c8-36b25934831b"
      },
      "source": [
        "col_start=7\n",
        "df[\"best_idf\"]=df.iloc[:,col_start:].idxmax(axis=1)\n",
        "#df[\"best_idf\"]= [2583 if (s.sum()==0) else df.iloc[:,col_start:].idxmax(axis=1) for s in df.iloc[:,1col_start1:]]\n",
        "#gestion des cas où toutes les colonnes valent 0\n",
        "#on affecte la classe 2583 (majoritaire)\n",
        "for i in range(len(df)):\n",
        "  sum = df.iloc[i,col_start:].sum()\n",
        "  if (sum == 0):\n",
        "    df[\"best_idf\"][i]=\"2583\"\n",
        "\n",
        "print(\"#Articles:\", len(df))\n",
        "print(df[\"best_idf\"].value_counts())\n",
        "#path = '/Drive/My Drive/Projet Rakuten'\n",
        "#df.to_csv(f'{path}/damien.csv')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-ee6136992f17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#on affecte la classe 2583 (majoritaire)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0msum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcol_start\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"best_idf\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"2583\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mstat_func\u001b[0;34m(self, axis, skipna, level, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[1;32m  11432\u001b[0m             \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11433\u001b[0m             \u001b[0mnumeric_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 11434\u001b[0;31m             \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  11435\u001b[0m         )\n\u001b[1;32m  11436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   4247\u001b[0m                 )\n\u001b[1;32m   4248\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4249\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4251\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_reindex_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36m_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvalid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0;31m# we want to transform an object array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mnansum\u001b[0;34m(values, axis, skipna, min_count, mask)\u001b[0m\n\u001b[1;32m    507\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_timedelta64_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0mdtype_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m     \u001b[0mthe_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_sum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    510\u001b[0m     \u001b[0mthe_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_maybe_null_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthe_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     45\u001b[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n\u001b[1;32m     46\u001b[0m          initial=_NoValue, where=True):\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m def _prod(a, axis=None, dtype=None, out=None, keepdims=False,\n",
            "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"numpy.float64\") to str"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ATKh3CW_nhh"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwCdBCpE_hXp"
      },
      "source": [
        "#Expressions régulières pour identifier les différentes unités\n",
        "#TODO transformer en numérique pas en liste\n",
        "import re\n",
        "\n",
        "#nombre de nombres à 2 chiffres ou +\n",
        "r = re.compile(\"[0-9]{2,}\") \n",
        "df['desi_nb2chiffres+']= df['designation'].apply(lambda x: min(1,len(r.findall(x))))\n",
        "df['desc_nb2chiffres+']= df['description'].apply(lambda x: min(1,len(r.findall(x))))\n",
        "#XGo ou XMo ou XTo\n",
        "#r = re.compile(\"([\\d.]+)\\s?(go|mo|to|Go|Mo|To|giga|gigas)\") \n",
        "#df['desi_Go']=df['designation'].apply(lambda x: min(1,len(r.findall(x))))\n",
        "#df['desc_Go']=df['description'].apply(lambda x: min(1,len(r.findall(x))))\n",
        "#N°X\n",
        "r = re.compile(\"(numéro )\") \n",
        "df['desi_num']=df['designation'].apply(lambda x: min(1,len(r.findall(x))))\n",
        "df['desi_num']=df['designation'].apply(lambda x: min(1,len(r.findall(x))))\n",
        "r = re.compile(\"[Nn][°]\\s?[\\d]+\") \n",
        "#df['desi_num']=df['designation'].apply(lambda x: min(1,len(r.findall(x))))\n",
        "df['desc_num']=df['description'].apply(lambda x: min(1,len(r.findall(x))))\n",
        "#Poids kg Kg mg g\n",
        "r = re.compile(\"[0-9\\.]+[kKm]?[g]\") #([\\d.]+)\\s+(lbs?|oz|g|kg) \n",
        "r = re.compile(\"([\\d.]+)\\s?(KG|Kg|g|kg|mg)[\\s.]\") #(nombres ou .)+ / (espace)+ / (kg mg ..)\n",
        "df['desi_poids']=df['designation'].apply(lambda x: min(1,len(r.findall(x))))\n",
        "df['desc_poids']=df['description'].apply(lambda x: min(1,len(r.findall(x))))\n",
        "#Taille cm mm m\n",
        "r = re.compile(\"([\\d.]+)\\s?(cm|mm|m|M)[\\s.]\") \n",
        "df['desi_long']=df['designation'].apply(lambda x: min(1,len(r.findall(x))))\n",
        "df['desc_long']=df['description'].apply(lambda x: min(1,len(r.findall(x))))\n",
        "#Volume mL cL dL\n",
        "r = re.compile(\"([\\d.]+)\\s?(mL|L|ml|l|cl)[\\s.]\") \n",
        "df['desi_vol']=df['designation'].apply(lambda x: min(1,len(r.findall(x))))\n",
        "df['desc_vol']=df['description'].apply(lambda x: min(1,len(r.findall(x))))\n",
        "#Age\n",
        "r = re.compile(\"([\\d.]+)\\s?(an|ans|An|Ans|mois|Mois)[\\s.]\") \n",
        "df['desi_ans_mois']=df['designation'].apply(lambda x: min(1,len(r.findall(x))))\n",
        "df['desc_ans_mois']=df['description'].apply(lambda x: min(1,len(r.findall(x))))\n",
        "#Pièces\n",
        "r = re.compile(\"([\\d.]+)\\s?(pc|pcs|pièces|pièce)[\\s.]\") \n",
        "df['desi_pieces']=df['designation'].apply(lambda x: min(1,len(r.findall(x))))\n",
        "df['desc_pieces']=df['description'].apply(lambda x: min(1,len(r.findall(x))))\n",
        "#%\n",
        "#r = re.compile(\"([\\d.]+)\\s?%\") \n",
        "#df['desi_pourcent']=df['designation'].apply(lambda x: min(1,len(r.findall(x))))\n",
        "#df['desc_pourcent']=df['description'].apply(lambda x: min(1,len(r.findall(x))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSLGvHt49K2C"
      },
      "source": [
        "import re\n",
        "def feature(df) :\n",
        "    df['desi_word_count'] = df['designation'].apply(lambda x : len(str(x).split()))\n",
        "    df['desi_char_count (w/o space)'] = df['designation'].apply(lambda x : len(x.replace(\" \",\"\")))\n",
        "    #df['desi_word_density'] = df['desi_word_count'] / (df['desi_char_count'] + 1)\n",
        "    df['desi_total_length'] = df['designation'].apply(len)\n",
        "    #df['desi_capitals'] = df['designation'].apply(lambda comment: sum(1 for c in comment if c.isupper()))\n",
        "    # df['desi_caps_vs_length'] = df.apply(lambda row: float(row['desi_capitals'])/float(row['desi_total_length']),axis=1)\n",
        "    df['desi_num_exclamation_marks'] =df['designation'].apply(lambda x: x.count('!'))\n",
        "    df['desi_num_question_marks'] = df['designation'].apply(lambda x: x.count('?'))\n",
        "    #df['desi_num_punctuation'] = df['designation'].apply(lambda x: sum(x.count(w) for w in '.,;:'))\n",
        "    #df['desi_num_symbols'] = df['designation'].apply(lambda x: sum(str(x).count(w) for w in '*&$%+-/'))\n",
        "    df['desi_num_unique_words'] = df['designation'].apply(lambda x: len(set(w for w in x.split())))\n",
        "    df['desi_words_vs_unique'] = df['desi_num_unique_words'] / df['desi_word_count']\n",
        "    df[\"desi_word_unique_percent\"] =  df[\"desi_num_unique_words\"]*100/df['desi_word_count']\n",
        "    \n",
        "    df['descri_word_count'] = df['description'].apply(lambda x : len(str(x).split()))\n",
        "    df['descri_char_count (w/o space)'] = df['description'].apply(lambda x : len(str(x).replace(\" \",\"\")))\n",
        "    #df['descri_word_density'] = df['descri_word_count'] / (df['descri_char_count'] + 1)\n",
        "    df['descri_total_length'] = df['description'].apply(lambda x :len(str(x)))\n",
        "   # df['descri_capitals'] = df['description'].apply(lambda comment: sum(1 for c in str(comment) if c.isupper()))\n",
        "    # df['descri_caps_vs_length'] = df.apply(lambda row: float(row['descri_capitals'])/float(row['descri_total_length']),axis=1)\n",
        "    df['descri_num_exclamation_marks'] =df['description'].apply(lambda x: str(x).count('!'))\n",
        "    df['descri_num_question_marks'] = df['description'].apply(lambda x: str(x).count('?'))\n",
        "    #df['descri_num_punctuation'] = df['description'].apply(lambda x: sum(str(x).count(w) for w in '.,;:'))\n",
        "   # df['descri_num_symbols'] = df['description'].apply(lambda x: sum(str(x).count(w) for w in '*&$%'))\n",
        "    df['descri_num_unique_words'] = df['description'].apply(lambda x: len(set(w for w in str(x).split())))\n",
        "    df['descri_words_vs_unique'] = df['descri_num_unique_words'] / df['descri_word_count']\n",
        "    df[\"descri_word_unique_percent\"] =  df[\"descri_num_unique_words\"]*100/df['descri_word_count']\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "id": "3IifvcEo9LE4",
        "outputId": "823cdb61-3dc9-4c11-f687-5d1001dfedc0"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>designation</th>\n",
              "      <th>description</th>\n",
              "      <th>productid</th>\n",
              "      <th>prdtypecode</th>\n",
              "      <th>desi_nb_phrases</th>\n",
              "      <th>desc_nb_phrases</th>\n",
              "      <th>best_idf</th>\n",
              "      <th>class_10.0</th>\n",
              "      <th>class_40.0</th>\n",
              "      <th>class_50.0</th>\n",
              "      <th>class_60.0</th>\n",
              "      <th>class_1140.0</th>\n",
              "      <th>class_1160.0</th>\n",
              "      <th>class_1180.0</th>\n",
              "      <th>class_1280.0</th>\n",
              "      <th>class_1281.0</th>\n",
              "      <th>class_1300.0</th>\n",
              "      <th>class_1301.0</th>\n",
              "      <th>class_1302.0</th>\n",
              "      <th>class_1320.0</th>\n",
              "      <th>class_1560.0</th>\n",
              "      <th>class_1920.0</th>\n",
              "      <th>class_1940.0</th>\n",
              "      <th>class_2060.0</th>\n",
              "      <th>class_2220.0</th>\n",
              "      <th>class_2280.0</th>\n",
              "      <th>class_2403.0</th>\n",
              "      <th>class_2462.0</th>\n",
              "      <th>class_2522.0</th>\n",
              "      <th>class_2582.0</th>\n",
              "      <th>class_2583.0</th>\n",
              "      <th>class_2585.0</th>\n",
              "      <th>class_2705.0</th>\n",
              "      <th>class_2905.0</th>\n",
              "      <th>desc_nb2chiffres+</th>\n",
              "      <th>desi_num</th>\n",
              "      <th>desc_num</th>\n",
              "      <th>desc_poids</th>\n",
              "      <th>desc_long</th>\n",
              "      <th>desc_vol</th>\n",
              "      <th>desc_ans_mois</th>\n",
              "      <th>desc_pieces</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>voici désignation</td>\n",
              "      <td>voici description</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2583</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         designation        description  ...  desc_ans_mois desc_pieces\n",
              "0  voici désignation  voici description  ...              0           0\n",
              "\n",
              "[1 rows x 42 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2x9VFofBR1V"
      },
      "source": [
        "if (isSaveData):\n",
        "  df.to_csv(f'{pathSaveCsv}/features_texte.csv')"
      ],
      "execution_count": 35,
      "outputs": []
    }
  ]
}